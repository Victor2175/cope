{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "418fd1e3-b409-42d8-a83a-4ad7504bebaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [100/1000], Loss: 0.5044\n",
      "Epoch [200/1000], Loss: 0.3795\n",
      "Epoch [300/1000], Loss: 0.3694\n",
      "Epoch [400/1000], Loss: 0.3578\n",
      "Epoch [500/1000], Loss: 0.3454\n",
      "Epoch [600/1000], Loss: 0.3326\n",
      "Epoch [700/1000], Loss: 0.3196\n",
      "Epoch [800/1000], Loss: 0.3069\n",
      "Epoch [900/1000], Loss: 0.2946\n",
      "Epoch [1000/1000], Loss: 0.2829\n",
      "Learned shared feature matrix W_shared:\n",
      "Parameter containing:\n",
      "tensor([[ 0.0050, -0.0863,  0.0885, -0.0899, -0.0873],\n",
      "        [-0.5076, -0.0011,  0.0149,  0.0125, -0.0240],\n",
      "        [ 0.0505,  0.0372, -0.0366,  0.0371,  0.0370],\n",
      "        [-0.2631, -0.2566,  0.2592, -0.2586, -0.2607],\n",
      "        [ 0.2818, -0.1807,  0.1798, -0.1965, -0.1695],\n",
      "        [-0.7366, -0.1411,  0.1514, -0.1267, -0.1626],\n",
      "        [ 0.9508,  0.4917, -0.5236,  0.4766,  0.5322],\n",
      "        [ 0.4060,  0.5401, -0.5516,  0.5512,  0.5630],\n",
      "        [-0.7428,  0.2510, -0.2543,  0.2862,  0.2321],\n",
      "        [-0.8807,  0.3548, -0.3592,  0.3948,  0.3330]], requires_grad=True)\n",
      "Learned task-specific weight matrices W_task:\n",
      "Task 1 weights:\n",
      "Parameter containing:\n",
      "tensor([[-1.3943],\n",
      "        [-0.8596],\n",
      "        [ 0.8549],\n",
      "        [-0.8517],\n",
      "        [-0.8671]], requires_grad=True)\n",
      "Task 2 weights:\n",
      "Parameter containing:\n",
      "tensor([[ 1.3652],\n",
      "        [-0.7673],\n",
      "        [ 0.7361],\n",
      "        [-0.8231],\n",
      "        [-0.6974]], requires_grad=True)\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "def multi_task_feature_learning(X_tasks, Y_tasks, d_shared, lr=1e-3, num_epochs=1000, lambda_reg=0.1):\n",
    "    \"\"\"\n",
    "    Implements Multi-Task Feature Learning using PyTorch.\n",
    "\n",
    "    Parameters:\n",
    "        X_tasks (list of torch.Tensor): Input data for each task. Each tensor has shape (n_samples, d_features).\n",
    "        Y_tasks (list of torch.Tensor): Output data for each task. Each tensor has shape (n_samples, ).\n",
    "        d_shared (int): Dimensionality of the shared feature space.\n",
    "        lr (float): Learning rate for the optimizer.\n",
    "        num_epochs (int): Number of training epochs.\n",
    "        lambda_reg (float): Regularization coefficient for shared feature space.\n",
    "\n",
    "    Returns:\n",
    "        W_shared (torch.Tensor): Learned shared feature matrix.\n",
    "        W_task (list of torch.Tensor): Learned task-specific weight matrices.\n",
    "    \"\"\"\n",
    "    # Check number of tasks\n",
    "    num_tasks = len(X_tasks)\n",
    "    if num_tasks != len(Y_tasks):\n",
    "        raise ValueError(\"Number of tasks in X_tasks and Y_tasks must match.\")\n",
    "\n",
    "    # Dimensionality of input features\n",
    "    d_features = X_tasks[0].shape[1]\n",
    "\n",
    "    # Initialize shared feature matrix (d_features x d_shared)\n",
    "    W_shared = nn.Parameter(torch.randn(d_features, d_shared) * 0.01)\n",
    "\n",
    "    # Initialize task-specific weight matrices (d_shared x 1 per task)\n",
    "    W_task = [nn.Parameter(torch.randn(d_shared, 1) * 0.01) for _ in range(num_tasks)]\n",
    "\n",
    "    # Optimizer\n",
    "    optimizer = optim.Adam([W_shared] + W_task, lr=lr)\n",
    "\n",
    "    # Loss function\n",
    "    criterion = nn.MSELoss()\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        total_loss = 0\n",
    "\n",
    "        # Zero gradients\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        for task_idx in range(num_tasks):\n",
    "            X = X_tasks[task_idx]\n",
    "            Y = Y_tasks[task_idx].view(-1, 1)  # Ensure Y is a column vector\n",
    "\n",
    "            # Forward pass: shared features and task-specific prediction\n",
    "            Z = X @ W_shared  # Project input into shared space\n",
    "            Y_pred = Z @ W_task[task_idx]  # Task-specific prediction\n",
    "\n",
    "            # Compute task loss\n",
    "            task_loss = criterion(Y_pred, Y)\n",
    "            total_loss += task_loss\n",
    "\n",
    "        # Add regularization term for shared feature matrix\n",
    "        reg_loss = lambda_reg * torch.norm(W_shared, p='fro')\n",
    "        total_loss += reg_loss\n",
    "\n",
    "        # Backward pass and optimization\n",
    "        total_loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # Print loss every 100 epochs\n",
    "        if (epoch + 1) % 100 == 0:\n",
    "            print(f\"Epoch [{epoch + 1}/{num_epochs}], Loss: {total_loss.item():.4f}\")\n",
    "\n",
    "    return W_shared, W_task\n",
    "\n",
    "# Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Generate synthetic data for two tasks\n",
    "    torch.manual_seed(42)\n",
    "    \n",
    "    # Task 1\n",
    "    X_task1 = torch.randn(100, 10)\n",
    "    W_true_task1 = torch.randn(10, 1)\n",
    "    Y_task1 = X_task1 @ W_true_task1 + 0.1 * torch.randn(100, 1)\n",
    "\n",
    "    # Task 2\n",
    "    X_task2 = torch.randn(100, 10)\n",
    "    W_true_task2 = torch.randn(10, 1)\n",
    "    Y_task2 = X_task2 @ W_true_task2 + 0.1 * torch.randn(100, 1)\n",
    "\n",
    "    # Combine tasks\n",
    "    X_tasks = [X_task1, X_task2]\n",
    "    Y_tasks = [Y_task1, Y_task2]\n",
    "\n",
    "    # Train the model\n",
    "    W_shared, W_task = multi_task_feature_learning(X_tasks, Y_tasks, d_shared=5, lr=1e-2, num_epochs=1000, lambda_reg=0.1)\n",
    "\n",
    "    print(\"Learned shared feature matrix W_shared:\")\n",
    "    print(W_shared)\n",
    "    print(\"Learned task-specific weight matrices W_task:\")\n",
    "    for idx, W in enumerate(W_task):\n",
    "        print(f\"Task {idx + 1} weights:\")\n",
    "        print(W)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
