{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42fa77a2-e924-4f51-8882-811bf103744a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in ' /net/atmos/data/cmip6-ng/tos/ann/g025 ' :\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_39535/1368350178.py:73: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble = np.nanmean(dic_processed_ssp585[m][i][131:164,:,:],axis=0)/ len(dic_processed_ssp585[m])\n",
      "/tmp/ipykernel_39535/1368350178.py:75: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble += np.nanmean(dic_processed_ssp585[m][i][131:164,:,:],axis=0)/ len(dic_processed_ssp585[m])\n"
     ]
    }
   ],
   "source": [
    "from robust_analysis import train_ridge_regression, train_robust_model, compute_weights,\\\n",
    "                            leave_one_out, leave_one_out_procedure, cross_validation_loo\n",
    "\n",
    "import pickle\n",
    "import os \n",
    "import netCDF4 as netcdf\n",
    "import skimage\n",
    "import numpy as np\n",
    "\n",
    "with open('ssp585_time_series.pkl', 'rb') as f:\n",
    "    dic_ssp585 = pickle.load(f)\n",
    "\n",
    "# Get the list of all files and directories\n",
    "path = \"/net/atmos/data/cmip6-ng/tos/ann/g025\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "list_model = []\n",
    "list_forcing = []\n",
    "\n",
    "for idx, file in enumerate(dir_list):\n",
    "\n",
    "    file_split = file.split(\"_\")\n",
    "    \n",
    "    # extract model names\n",
    "    model_name = file_split[2]\n",
    "    forcing = file_split[3]\n",
    "    run_name = file_split[4]\n",
    "    \n",
    "    list_model.append(model_name)\n",
    "    list_forcing.append(forcing)\n",
    "    \n",
    "model_names = list(set(list_model))\n",
    "forcing_names = list(set(list_forcing))\n",
    "\n",
    "\n",
    "# define the file\n",
    "file = '/net/h2o/climphys3/simondi/cope-analysis/data/erss/sst_annual_g050_mean_19812014_centered.nc'\n",
    "\n",
    "# read the dataset\n",
    "file2read = netcdf.Dataset(file,'r')\n",
    "\n",
    "# load longitude, latitude and sst monthly means\n",
    "lon = np.array(file2read.variables['lon'][:])\n",
    "lat = np.array(file2read.variables['lat'][:])\n",
    "sst = np.array(file2read.variables['sst'])\n",
    "\n",
    "# define grid\n",
    "lat_grid, lon_grid = np.meshgrid(lat, lon, indexing='ij')\n",
    "\n",
    "# first filter out the models that do not contain ensemble members \n",
    "dic_reduced_ssp585 = {}\n",
    "\n",
    "for m in list(dic_ssp585.keys()):\n",
    "    if len(dic_ssp585[m].keys()) > 2:\n",
    "        dic_reduced_ssp585[m] = dic_ssp585[m].copy()\n",
    "        for idx_i, i in enumerate(dic_ssp585[m].keys()):\n",
    "            dic_reduced_ssp585[m][i] = skimage.transform.downscale_local_mean(dic_reduced_ssp585[m][i],(1,2,2))\n",
    "\n",
    "\n",
    "# second, for each model we compute the anomalies \n",
    "dic_processed_ssp585 = {}\n",
    "\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    dic_processed_ssp585[m] = dic_reduced_ssp585[m].copy()\n",
    "    \n",
    "    mean_ref_ensemble = 0\n",
    "    for idx_i, i in enumerate(dic_reduced_ssp585[m].keys()):\n",
    "        \n",
    "        if idx_i == 0:\n",
    "            mean_ref_ensemble = np.nanmean(dic_processed_ssp585[m][i][131:164,:,:],axis=0)/ len(dic_processed_ssp585[m])\n",
    "        else:\n",
    "            mean_ref_ensemble += np.nanmean(dic_processed_ssp585[m][i][131:164,:,:],axis=0)/ len(dic_processed_ssp585[m])\n",
    "    \n",
    "    for idx_i, i in enumerate(dic_processed_ssp585[m].keys()):\n",
    "        dic_processed_ssp585[m][i] = dic_processed_ssp585[m][i] - mean_ref_ensemble\n",
    "\n",
    "\n",
    "# compute the forced response\n",
    "dic_forced_response_ssp585 = dict({})\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    dic_forced_response_ssp585[m] = dic_reduced_ssp585[m].copy()\n",
    "    \n",
    "    mean_spatial_ensemble = 0\n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):\n",
    "        \n",
    "        if idx_i == 0:\n",
    "            mean_spatial_ensemble = np.nanmean(dic_forced_response_ssp585[m][i],axis=(1, 2))/ len(dic_forced_response_ssp585[m])\n",
    "        else:\n",
    "            mean_spatial_ensemble += np.nanmean(dic_forced_response_ssp585[m][i],axis=(1, 2))/ len(dic_forced_response_ssp585[m])\n",
    "            \n",
    "    \n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):\n",
    "        \n",
    "        dic_forced_response_ssp585[m][i] = mean_spatial_ensemble - np.mean(mean_spatial_ensemble[131:164])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76b83538-eccf-4715-8069-91b9fb22674e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build the "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
