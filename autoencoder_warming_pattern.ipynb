{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0bd0c17d",
   "metadata": {},
   "source": [
    "## Load the data in pickle file "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbbbc114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the data\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import netCDF4 as netcdf\n",
    "\n",
    "with open('ssp585_time_series.pkl', 'rb') as f:\n",
    "    dic_ssp585 = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aae8d435",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files and directories in ' /net/atmos/data/cmip6-ng/tos/ann/g025 ' :\n"
     ]
    }
   ],
   "source": [
    "import os \n",
    "\n",
    "# Get the list of all files and directories\n",
    "path = \"/net/atmos/data/cmip6-ng/tos/ann/g025\"\n",
    "dir_list = os.listdir(path)\n",
    "\n",
    "print(\"Files and directories in '\", path, \"' :\")\n",
    "\n",
    "list_model = []\n",
    "list_forcing = []\n",
    "\n",
    "for idx, file in enumerate(dir_list):\n",
    "\n",
    "    file_split = file.split(\"_\")\n",
    "    \n",
    "    # extract model names\n",
    "    model_name = file_split[2]\n",
    "    forcing = file_split[3]\n",
    "    run_name = file_split[4]\n",
    "    \n",
    "    list_model.append(model_name)\n",
    "    list_forcing.append(forcing)\n",
    "    \n",
    "model_names = list(set(list_model))\n",
    "forcing_names = list(set(list_forcing))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e5b406d-a1c4-4d04-a0d6-533cdb9d20c1",
   "metadata": {},
   "source": [
    "### Load the real observations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "537f445b-9bdb-4722-bc2a-1e1d61e614ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import netCDF4 as netcdf\n",
    "\n",
    "# define the file\n",
    "file = '/net/h2o/climphys3/simondi/cope-analysis/data/erss/sst_annual_g050_mean_19812014_centered.nc'\n",
    "\n",
    "# read the dataset\n",
    "file2read = netcdf.Dataset(file,'r')\n",
    "\n",
    "# load longitude, latitude and sst monthly means\n",
    "lon = np.array(file2read.variables['lon'][:])\n",
    "lat = np.array(file2read.variables['lat'][:])\n",
    "sst = np.array(file2read.variables['sst'])\n",
    "\n",
    "# define grid\n",
    "lat_grid, lon_grid = np.meshgrid(lat, lon, indexing='ij')\n",
    "\n",
    "time_period = 33\n",
    "grid_lat_size = lat.shape[0]\n",
    "grid_lon_size = lon.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d80c79c",
   "metadata": {},
   "source": [
    "# Preprocessing of the data: $(x_{i,t,m}^{p})_{i=1,\\ldots,I, t=1,\\ldots,T,m=1,\\ldots,M, p=1,\\ldots,d}$\n",
    "## $i$: ensemble member (run) index\n",
    "## $t$: time index\n",
    "## $m$: model index\n",
    "## $p$: grid cell index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bccdb2dc-7360-45d3-acfc-0d6b7cd15e80",
   "metadata": {},
   "source": [
    "#### Keep the model with at least 3 ensemble memebers and downscale the data from latitude 144 -> 36 with local averaging (to match with ensemble methods"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ea7e6d84",
   "metadata": {},
   "outputs": [],
   "source": [
    "import skimage\n",
    "\n",
    "# first filter out the models that do not contain ensemble members \n",
    "dic_reduced_ssp585 = {}\n",
    "\n",
    "for m in list(dic_ssp585.keys()):\n",
    "    if len(dic_ssp585[m].keys()) > 2:\n",
    "        dic_reduced_ssp585[m] = dic_ssp585[m].copy()\n",
    "        for idx_i, i in enumerate(dic_ssp585[m].keys()):\n",
    "            dic_reduced_ssp585[m][i] = skimage.transform.downscale_local_mean(dic_reduced_ssp585[m][i],(1,2,2))\n",
    "            lat_size = dic_reduced_ssp585[m][i][0,:,:].shape[0]\n",
    "            lon_size = dic_reduced_ssp585[m][i][0,:,:].shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3cb65a6-c532-4067-a774-b723c93ea7c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "nan_idx = []\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    for idx_i,i in enumerate(dic_reduced_ssp585[m].keys()):    \n",
    "        # for t in enumerate(range(time_period)[:2]):\n",
    "            # print(np.where(np.isnan(dic_reduced_ssp585[m][i][t,:,:].ravel())==True))\n",
    "        nan_idx_tmp = list(np.where(np.isnan(dic_reduced_ssp585[m][i][0,:,:].ravel())==True)[0])\n",
    "        # nan_idx_tmp_tt = list(np.where(np.isnan(dic_reduced_ssp585[m][i][1,:,:].ravel())==True)[0])\n",
    "        \n",
    "        nan_idx = list(set(nan_idx) | set(nan_idx_tmp))\n",
    "\n",
    "notnan_idx = list(set(list(range(lon_size*lat_size))) - set(nan_idx))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a03b8a2b",
   "metadata": {},
   "source": [
    "### 1) Compute anomalies: $\\displaystyle \\overline{x}_{i,t,m}^p = x_{i,t,m}^p - \\frac{1}{t_{\\mathrm{ref}}^f - t_{\\mathrm{ref}}^s} \\sum_{t= t_{\\mathrm{ref}}^s}^{t_{\\mathrm{ref}}^f} \\sum_{i=1}^I x_{i,t,m}^p$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0cbf3f5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_48001/3205467388.py:16: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble = np.nanmean(y_tmp,axis=0)/ len(dic_reduced_ssp585[m].keys())\n",
      "/tmp/ipykernel_48001/3205467388.py:18: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble += np.nanmean(y_tmp,axis=0)/ len(dic_reduced_ssp585[m].keys())\n"
     ]
    }
   ],
   "source": [
    "# second, for each model we compute the anomalies \n",
    "dic_processed_ssp585 = {}\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    dic_processed_ssp585[m] = dic_reduced_ssp585[m].copy()\n",
    "    \n",
    "    mean_ref_ensemble = 0\n",
    "    for idx_i, i in enumerate(dic_reduced_ssp585[m].keys()):\n",
    "        y_tmp = dic_reduced_ssp585[m][i][131:164,:,:].copy().reshape(time_period, lat_size*lon_size)\n",
    "        y_tmp[:,nan_idx] = float('nan')\n",
    "        \n",
    "        \n",
    "        if idx_i == 0:\n",
    "            mean_ref_ensemble = np.nanmean(y_tmp,axis=0)/ len(dic_reduced_ssp585[m].keys())\n",
    "        else:\n",
    "            mean_ref_ensemble += np.nanmean(y_tmp,axis=0)/ len(dic_reduced_ssp585[m].keys())\n",
    "\n",
    "    for idx_i, i in enumerate(dic_processed_ssp585[m].keys()):\n",
    "        dic_processed_ssp585[m][i] = y_tmp - mean_ref_ensemble"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f5c4750",
   "metadata": {},
   "source": [
    "### 2) Compute the forced response: \n",
    "#### - Mean over space: $\\displaystyle y_{i,t,m} = \\frac{1}{P} \\sum_{p=1}^P x_{i,t,m}^p$\n",
    "#### - Mean over ensemble members: $\\displaystyle \\overline{y}_{t,m} = \\frac{1}{I} \\sum_{i=1}^I y_{i,t,m}$\n",
    "#### - Set the mean to all the ensemble member forced responses: $y_{i,t,m} \\colon= \\overline{y}_{t,m}$\n",
    "#### - Centering with respect to a given reference period: $\\displaystyle y_{i,t,m} = y_{i,t,m} - \\frac{1}{t_{\\mathrm{ref}}^f - t_{\\mathrm{ref}}^s} \\sum_{t= t_{\\mathrm{ref}}^s}^{t_{\\mathrm{ref}}^f} \\overline{y}_{t,m}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "91564186",
   "metadata": {},
   "outputs": [],
   "source": [
    "# compute the forced response\n",
    "dic_forced_response_ssp585 = dict({})\n",
    "dic_forced_response_ssp585_tmp = {}\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    dic_forced_response_ssp585[m] = dic_reduced_ssp585[m].copy()\n",
    "    dic_forced_response_ssp585_tmp[m] = dic_reduced_ssp585[m].copy()\n",
    "\n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):\n",
    "        \n",
    "        y_tmp = dic_reduced_ssp585[m][i][131:164,:,:].copy().reshape(time_period, lat_size*lon_size)\n",
    "        y_tmp[:,nan_idx] = float('nan')\n",
    "\n",
    "        if idx_i == 0:\n",
    "            mean_spatial_ensemble = y_tmp/ len(dic_forced_response_ssp585[m].keys())\n",
    "        else:\n",
    "            mean_spatial_ensemble += y_tmp/ len(dic_forced_response_ssp585[m].keys())\n",
    "\n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):        \n",
    "        dic_forced_response_ssp585[m][i] = mean_spatial_ensemble - np.nanmean(mean_spatial_ensemble)\n",
    "    dic_forced_response_ssp585_tmp[m] = mean_spatial_ensemble - np.nanmean(mean_spatial_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "022aa43e",
   "metadata": {},
   "source": [
    "## Now we can use the data to run some simple regression models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4d985092",
   "metadata": {},
   "outputs": [],
   "source": [
    "time_period = 33\n",
    "grid_lat_size = 36\n",
    "grid_lon_size = 72"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "21ec331b",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forced_response = {}\n",
    "x_predictor = {}\n",
    "\n",
    "for idx_m,m in enumerate(dic_processed_ssp585.keys()):\n",
    "    y_forced_response[m] = {}\n",
    "    x_predictor[m] = {}\n",
    "\n",
    "    y_forced_response[m] = dic_forced_response_ssp585_tmp[m]\n",
    "    \n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):\n",
    "        \n",
    "        x_predictor[m][i] = dic_processed_ssp585[m][i]\n",
    "        x_predictor[m][i][:,nan_idx] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "136e5b95-3b7d-42b1-9fcd-574b0671e7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_forced_response_concatenate = {}\n",
    "x_predictor_concatenate = {}\n",
    "count_x = 0\n",
    "\n",
    "\n",
    "for idx_m,m in enumerate(dic_processed_ssp585.keys()):\n",
    "    y_forced_response_concatenate[m] = 0\n",
    "    x_predictor_concatenate[m] = 0\n",
    "\n",
    "    for idx_i, i in enumerate(dic_forced_response_ssp585[m].keys()):\n",
    "        count_x += len(dic_processed_ssp585[m].keys())*33\n",
    "        \n",
    "        if idx_i ==0:\n",
    "            y_forced_response_concatenate[m] = dic_forced_response_ssp585[m][i]\n",
    "            x_predictor_concatenate[m] = dic_processed_ssp585[m][i]\n",
    "        else:\n",
    "            y_forced_response_concatenate[m] = np.concatenate([y_forced_response_concatenate[m],dic_forced_response_ssp585[m][i]])\n",
    "            x_predictor_concatenate[m] = np.concatenate([x_predictor_concatenate[m], dic_processed_ssp585[m][i]],axis=0)  \n",
    "    x_predictor_concatenate[m][:,nan_idx] = float('nan')\n",
    "    y_forced_response_concatenate[m][:,nan_idx] = float('nan')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a4af30e7-c7e1-4b52-9653-9cb02d1659ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "\n",
    "# Data preprocessing\n",
    "x_train = {}\n",
    "y_train = {}\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    x_train[m] = torch.nan_to_num(torch.from_numpy(x_predictor_concatenate[m])).to(torch.float64)\n",
    "    y_train[m] = torch.from_numpy(y_forced_response_concatenate[m]).to(torch.float64)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8d1606-bf15-4e72-8f6a-752051c7ea78",
   "metadata": {},
   "source": [
    "### Define deep autoencoder with Pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea05b7e-22b0-44c6-a1f9-88a46288b5dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "torch.set_default_dtype(torch.float64)\n",
    "\n",
    "# Define the Deep Autoencoder architecture\n",
    "class DeepAutoencoder(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size,output_size):\n",
    "        super(DeepAutoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Linear(input_size, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, hidden_size),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.Linear(hidden_size, 64),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(64, 128),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(128, output_size),\n",
    "            # nn.Sigmoid()  # Sigmoid activation for pixel values between 0 and 1\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "# Huber loss function\n",
    "class HuberLoss(nn.Module):\n",
    "    def __init__(self, delta=1.0):\n",
    "        super(HuberLoss, self).__init__()\n",
    "        self.delta = delta\n",
    "        self.loss = nn.SmoothL1Loss(reduction='mean')\n",
    "\n",
    "    def forward(self, y_true, y_pred):\n",
    "        residual = torch.abs(y_true - y_pred)\n",
    "        condition = (residual < self.delta).float()\n",
    "        loss = condition * 0.5 * residual ** 2 + (1 - condition) * (self.delta * residual - 0.5 * self.delta ** 2)\n",
    "        return torch.mean(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a18ab169-43a8-4672-9de5-e178bbeced89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def autoencoder_training(x,y,batch_number,input_size, hidden_size,output_size,num_epochs=100):\n",
    "    \n",
    "    # Create the Deep Autoencoder model\n",
    "    model = DeepAutoencoder(input_size, hidden_size, output_size)\n",
    "    \n",
    "    # Define least squares loss function and optimizer\n",
    "    criterion = nn.MSELoss()\n",
    "    # criterion = HuberLoss()\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=1e-2)\n",
    "\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "\n",
    "        loss = torch.tensor(0.0)\n",
    "        for i in range(batch_number):\n",
    "            \n",
    "            inputs = x[i*time_period:(i+1)*time_period,:].ravel().detach()\n",
    "        \n",
    "            # Forward pass\n",
    "            beta = model(inputs).reshape(time_period,grid_lon_size*grid_lat_size)\n",
    "            \n",
    "    \n",
    "            # Compute least squares loss\n",
    "            loss += criterion(y[i*time_period:(i+1)*time_period,:], torch.matmul(x[i*time_period:(i+1)*time_period,:],beta.reshape(grid_lon_size*grid_lat_size,grid_lon_size*grid_lat_size))) \\\n",
    "                    + 50*torch.norm(beta,p=2)**2\n",
    "            # loss += criterion(y[i*time_period:(i+1)*time_period,:], beta) \n",
    "                    \n",
    "\n",
    "        \n",
    "        # Backward pass and optimization\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "        # Print progress\n",
    "        if epoch%10==0:\n",
    "            print(f'Epoch [{epoch + 1}/{num_epochs}], Loss: {loss.item():.4f}')\n",
    "\n",
    "\n",
    "    return model,beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a585cd9e-0c14-4e6f-b9db-f212dcda4d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want X in R^{grid x runs*time steps}\n",
    "x_tmp = torch.zeros(count_x, lat_size*lon_size)\n",
    "y_tmp = torch.zeros(count_x, lat_size*lon_size)\n",
    "\n",
    "m0 = 'KACE-1-0-G'\n",
    "x_test = torch.zeros(len(x_predictor[m0].keys())*33, lat_size*lon_size)\n",
    "y_test = torch.zeros(len(x_predictor[m0].keys())*33, lat_size*lon_size)\n",
    "\n",
    "count_tmp =0\n",
    "\n",
    "for idx_m,m in enumerate(dic_reduced_ssp585.keys()):\n",
    "    if m != m0:\n",
    "\n",
    "        if count_tmp ==0:\n",
    "            x_tmp[:x_train[m].shape[0],:] = x_train[m]\n",
    "            y_tmp[:y_train[m].shape[0],:] = y_train[m]\n",
    "            count_tmp = x_train[m].shape[0]\n",
    "    \n",
    "        else:\n",
    "            x_tmp[count_tmp:count_tmp+x_train[m].shape[0],:] = x_train[m]\n",
    "            y_tmp[count_tmp:count_tmp+y_train[m].shape[0],:] = y_train[m]\n",
    "            count_tmp = x_train[m].shape[0]\n",
    "\n",
    "    else: \n",
    "        x_test = x_train[m]\n",
    "        y_test = y_train[m]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "10a636ed-3ed1-4ac0-a1f5-45481bc29dca",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'batch_number' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m hidden_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m20\u001b[39m\n\u001b[1;32m      4\u001b[0m output_size \u001b[38;5;241m=\u001b[39m grid_lon_size\u001b[38;5;241m*\u001b[39mgrid_lat_size\n\u001b[0;32m----> 6\u001b[0m model,beta \u001b[38;5;241m=\u001b[39m autoencoder_training(x_tmp,y_tmp,\u001b[43mbatch_number\u001b[49m,input_size, hidden_size,output_size,num_epochs\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m200\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'batch_number' is not defined"
     ]
    }
   ],
   "source": [
    "# input_size = x_train[m].shape[0]*grid_lon_size*grid_lat_size\n",
    "input_size = time_period*grid_lon_size*grid_lat_size\n",
    "hidden_size = 20\n",
    "output_size = grid_lon_size*grid_lat_size\n",
    "\n",
    "model,beta = autoencoder_training(x_tmp,y_tmp,batch_number,input_size, hidden_size,output_size,num_epochs=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77c96623-2bb6-43c8-872c-1057ef36007e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define beta to plot\n",
    "beta_tmp = beta.detach().clone()\n",
    "beta_tmp[nan_idx] = float('nan')\n",
    "beta_tmp = beta_tmp.detach().numpy().reshape(lat.shape[0],lon.shape[0])\n",
    "\n",
    "fig0 = plt.figure(figsize=(16,16))           \n",
    "\n",
    "ax0 = fig0.add_subplot(2, 2, 1)        \n",
    "ax0.set_title('Observations', size=7,pad=3.0)\n",
    "im0 = ax0.pcolormesh(lon_grid,lat_grid,beta_tmp,vmin=-0.00,vmax = 0.001)\n",
    "plt.colorbar(im0, ax=ax0, shrink=0.3)\n",
    "ax0.set_xlabel(r'x', size=7)\n",
    "ax0.set_ylabel(r'y', size=7)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de61b7a5-01c8-43ec-9fe1-6ce96f54fcf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "beta_pred = model(x_test[:33,:].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a228f9b5-da94-4cb5-9b21-54204a8add5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.mean((y_test.ravel()-torch.matmul(x_test,beta_pred))**2/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2f9e6b8-8e04-4c92-adc6-dbe2192210d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define beta to plot\n",
    "beta_tmp = beta.detach().clone()\n",
    "beta_tmp[nans_idx] = float('nan')\n",
    "beta_tmp = beta_tmp.detach().numpy().reshape(lat.shape[0],lon.shape[0])\n",
    "\n",
    "fig0 = plt.figure(figsize=(16,16))           \n",
    "\n",
    "ax0 = fig0.add_subplot(2, 2, 1)        \n",
    "ax0.set_title('Observations', size=7,pad=3.0)\n",
    "im0 = ax0.pcolormesh(lon_grid,lat_grid,beta_tmp,vmin=-0.00,vmax = 0.01)\n",
    "plt.colorbar(im0, ax=ax0, shrink=0.3)\n",
    "ax0.set_xlabel(r'x', size=7)\n",
    "ax0.set_ylabel(r'y', size=7)\n",
    "\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94d2af98-100a-479a-b083-5e4738fa6f40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "411c638b-a43a-422a-9b64-badf76b170db",
   "metadata": {},
   "source": [
    "# Deep Variational Autoencoder (VAE) with a a loss robust towards out-of-distribution samples"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
