{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e7a45e8a-08af-44dc-a677-e935c71a77c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "maindir = os.getcwd()\n",
    "sys.path.append(maindir+\"/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "2aa9d33d-e745-4093-a924-b4718041b7b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "from preprocessing import data_processing, compute_anomalies, extract_longitude_latitude, \\\n",
    "                            compute_forced_response, compute_variance, \\\n",
    "                            merge_runs, stack_runs, numpy_to_torch, standardize, build_training_and_test_sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5fe3cd9-ddda-44eb-b4a0-6fab4d686df3",
   "metadata": {},
   "outputs": [],
   "source": [
    "############### Load climate model raw data for SST\n",
    "with open('data/ssp585_time_series.pkl', 'rb') as f:\n",
    "    data = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ccaedc6d-a0a9-489a-9bda-0336d290a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "###################### Load longitude and latitude \n",
    "with open('data/lon.npy', 'rb') as f:\n",
    "    lon = np.load(f)\n",
    "\n",
    "with open('data/lat.npy', 'rb') as f:\n",
    "    lat = np.load(f)\n",
    "\n",
    "# define grid (+ croping for latitude > 60)\n",
    "lat_grid, lon_grid = np.meshgrid(lat[lat<=60], lon, indexing='ij')\n",
    "\n",
    "lat_size = lat_grid.shape[0]\n",
    "lon_size = lon_grid.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ee5898c7-0fdc-4461-9e38-bbc8ea84cf01",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vcohen/cope/src/preprocessing.py:110: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble = np.nanmean(y_tmp,axis=1)\n",
      "/home/vcohen/cope/src/preprocessing.py:111: RuntimeWarning: Mean of empty slice\n",
      "  mean_ref_ensemble = np.nanmean(mean_ref_ensemble,axis=0)\n",
      "/home/vcohen/cope/src/preprocessing.py:153: RuntimeWarning: Mean of empty slice\n",
      "  mean_spatial_ensemble = np.nanmean(y_tmp,axis=0)\n",
      "/home/vcohen/cope/src/preprocessing.py:157: RuntimeWarning: Mean of empty slice\n",
      "  data_forced_response[m][r] = mean_spatial_ensemble - np.nanmean(mean_spatial_ensemble,axis=0)\n"
     ]
    }
   ],
   "source": [
    "data_processed, notnan_idx, nan_idx = data_processing(data, lon, lat)\n",
    "x = compute_anomalies(data_processed, lon_size, lat_size, nan_idx, time_period=33)\n",
    "y = compute_forced_response(data_processed, lon_size, lat_size, nan_idx, time_period=33)\n",
    "vars = compute_variance(x, lon_size, lat_size, nan_idx, time_period=33)\n",
    "\n",
    "# convert numpy arrays to pytorch \n",
    "x, y, vars = numpy_to_torch(x,y,vars)\n",
    "\n",
    "# standardize data \n",
    "x, y = standardize(x,y,vars)\n",
    "\n",
    "# stack runs for each model\n",
    "x, y, vars = stack_runs(x,y,vars)\n",
    "\n",
    "# stack runs for each model\n",
    "x_merged, y_merged, vars_merged = merge_runs(x,y,vars)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448ea409-92f4-4d1f-9d22-d71e9cf8743c",
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 'CMCC-CM2-SR5'\n",
    "\n",
    "training_models, x_train, y_train, x_test, y_test = build_training_and_test_sets(m0,x,y,vars,lon_size,lat_size,time_period=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0a32b601-686b-4e88-9a28-9d3a8fe61960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import algorithms\n",
    "\n",
    "from algorithms import ridge_regression, ridge_regression_low_rank, low_rank_projection, \\\n",
    "                        prediction, train_robust_weights_model, compute_weights\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "11b96000-e64b-419a-a069-0ff374ceb4d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss function:  318449.1138850524\n",
      "Loss function:  345500.82303304394\n",
      "Loss function:  490400.6625835947\n",
      "Loss function:  545186.4922998112\n"
     ]
    }
   ],
   "source": [
    "# compute ridge regressor\n",
    "W_ridge = torch.zeros(lon_size*lat_size,lon_size*lat_size).to(torch.float64)\n",
    "W_ridge[np.ix_(notnan_idx,notnan_idx)] = ridge_regression(x_train[:,notnan_idx], y_train[:,notnan_idx], lambda_=50.0)\n",
    "\n",
    "# compute low rank ridge regressor\n",
    "r = 70\n",
    "W_rrr = torch.zeros(lon_size*lat_size,lon_size*lat_size).to(torch.float64)\n",
    "W_rrr[np.ix_(notnan_idx,notnan_idx)] = ridge_regression_low_rank(x_train[:,notnan_idx], y_train[:,notnan_idx], rank=r, lambda_=50.0)\n",
    "\n",
    "# compute low rank ridge regressor\n",
    "r = 10\n",
    "W_rrr = torch.zeros(lon_size*lat_size,lon_size*lat_size).to(torch.float64)\n",
    "W_rrr[np.ix_(notnan_idx,notnan_idx)] = ridge_regression_low_rank(x_train[:,notnan_idx], y_train[:,notnan_idx], rank=r, lambda_=50.0)\n",
    "\n",
    "# compute low rank ridge regressor\n",
    "r = 5\n",
    "W_rrr = torch.zeros(lon_size*lat_size,lon_size*lat_size).to(torch.float64)\n",
    "W_rrr[np.ix_(notnan_idx,notnan_idx)] = ridge_regression_low_rank(x_train[:,notnan_idx], y_train[:,notnan_idx], rank=r, lambda_=50.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3149d10c-c3e4-4515-b075-2241741ee9df",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 2400x1600 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from plot_tools import plot_gt_vs_pred, animation_gt_vs_pred\n",
    "\n",
    "plot_gt_vs_pred(y_test,x_test,W_ridge,notnan_idx,nan_idx,lon_grid,lat_grid,time_idx=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "0e63e8a4-eaa3-4272-b8b3-a535e1a7641f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.857421875\n",
      "Iteration  2 : Loss function :  23240.486328125\n",
      "Iteration  3 : Loss function :  21696.236328125\n",
      "Iteration  4 : Loss function :  20302.904296875\n",
      "Iteration  5 : Loss function :  18961.26953125\n",
      "Iteration  6 : Loss function :  17710.21875\n",
      "Iteration  7 : Loss function :  16603.578125\n",
      "Iteration  8 : Loss function :  15671.99609375\n",
      "Iteration  9 : Loss function :  14904.3193359375\n",
      "Iteration  10 : Loss function :  14274.9921875\n",
      "Iteration  11 : Loss function :  13757.783203125\n",
      "Iteration  12 : Loss function :  13330.53125\n",
      "Iteration  13 : Loss function :  12975.658203125\n",
      "Iteration  14 : Loss function :  12679.05078125\n",
      "Iteration  15 : Loss function :  12429.0791015625\n",
      "Iteration  16 : Loss function :  12216.1484375\n",
      "Iteration  17 : Loss function :  12032.4619140625\n",
      "Iteration  18 : Loss function :  11871.798828125\n",
      "Iteration  19 : Loss function :  11729.3076171875\n"
     ]
    }
   ],
   "source": [
    "w_robust, training_loss = train_robust_weights_model(training_models,x,y,lon_size,lat_size,notnan_idx,\\\n",
    "                                                       rank=None,lambda_=100.0,mu_=1000.0,\\\n",
    "                                                       lr=1e-5,nb_iterations=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f99b9a51-f2e9-48ae-be48-a4b24bc7e17b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vcohen/cope/src/algorithms.py:232: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  alpha = torch.nn.functional.softmax(alpha)\n"
     ]
    }
   ],
   "source": [
    "weights = compute_weights(training_models,w_robust,x,y,notnan_idx,lambda_=1.0,mu_=1.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3ab90bc0-f6df-45af-92a6-785091cbeca2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from leave_one_out import leave_one_out_single, leave_one_out_procedure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "8abd9d27-9817-477e-a510-4cbcdc3dc793",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.857421875\n",
      "Iteration  2 : Loss function :  23240.486328125\n",
      "Iteration  3 : Loss function :  21696.236328125\n",
      "Iteration  4 : Loss function :  20302.904296875\n"
     ]
    }
   ],
   "source": [
    "w_robust, y_pred, y_test, rmse_train = leave_one_out_single(m0,x,y,vars,\\\n",
    "                                         lon_size,lat_size,notnan_idx,nan_idx,time_period=33,\\\n",
    "                                         method='robust',rank=None,lambda_=100.0,mu_=1000.0,\\\n",
    "                                         lr=1e-5,nb_gradient_iterations=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f8724acc-ff14-414e-9e1a-24130ea4eb03",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 : Loss function :  16267.587890625\n",
      "Iteration  1 : Loss function :  13643.0439453125\n",
      "Iteration  2 : Loss function :  12195.38671875\n",
      "Iteration  3 : Loss function :  11598.857421875\n",
      "Iteration  4 : Loss function :  11357.97265625\n",
      "RMSE (mean) on model  ICON-ESM-LR  :  0.6858034909583546\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.36328125\n",
      "Iteration  4 : Loss function :  20303.44140625\n",
      "RMSE (mean) on model  EC-Earth3  :  0.15347330152767377\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.857421875\n",
      "Iteration  2 : Loss function :  23240.486328125\n",
      "Iteration  3 : Loss function :  21696.236328125\n",
      "Iteration  4 : Loss function :  20302.904296875\n",
      "RMSE (mean) on model  CMCC-CM2-SR5  :  0.2772097157787544\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.853515625\n",
      "Iteration  2 : Loss function :  23240.388671875\n",
      "Iteration  3 : Loss function :  21695.4375\n",
      "Iteration  4 : Loss function :  20298.9765625\n",
      "RMSE (mean) on model  ACCESS-CM2  :  0.32531072437372577\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.509765625\n",
      "Iteration  3 : Loss function :  21696.34375\n",
      "Iteration  4 : Loss function :  20303.359375\n",
      "RMSE (mean) on model  CESM2  :  0.23511561990331903\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.361328125\n",
      "Iteration  4 : Loss function :  20303.43359375\n",
      "RMSE (mean) on model  CNRM-ESM2-1  :  0.1895211962675345\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.36328125\n",
      "Iteration  4 : Loss function :  20303.44140625\n",
      "RMSE (mean) on model  IPSL-CM6A-LR  :  0.1261195884818589\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.5078125\n",
      "Iteration  3 : Loss function :  21696.294921875\n",
      "Iteration  4 : Loss function :  20303.037109375\n",
      "RMSE (mean) on model  GISS-E2-2-G  :  0.271334760845149\n",
      "Warning: Sum of weights is not equal to 1.0\n"
     ]
    }
   ],
   "source": [
    "w, rmse_mean, training_loss, weights = leave_one_out_procedure(x,y,vars,\\\n",
    "                                                            lon_size,lat_size, notnan_idx, nan_idx,time_period=33,\\\n",
    "                                                            method='robust',rank=None,lambda_=100.0,mu_=1000.0,\\\n",
    "                                                            lr=1e-5,nb_gradient_iterations=5,verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "0ba45b1a-2c2a-43f1-a7ab-6fb64d371597",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration  0 : Loss function :  16267.587890625\n",
      "Iteration  1 : Loss function :  13643.0439453125\n",
      "Iteration  2 : Loss function :  12195.38671875\n",
      "Iteration  3 : Loss function :  11598.857421875\n",
      "Iteration  4 : Loss function :  11357.97265625\n",
      "Iteration  5 : Loss function :  11174.283203125\n",
      "Iteration  6 : Loss function :  11006.6826171875\n",
      "Iteration  7 : Loss function :  10855.0439453125\n",
      "Iteration  8 : Loss function :  10716.2373046875\n",
      "Iteration  9 : Loss function :  10587.3154296875\n",
      "Iteration  10 : Loss function :  10466.6240234375\n",
      "Iteration  11 : Loss function :  10353.3876953125\n",
      "Iteration  12 : Loss function :  10247.3037109375\n",
      "Iteration  13 : Loss function :  10148.2265625\n",
      "Iteration  14 : Loss function :  10055.9794921875\n",
      "Iteration  15 : Loss function :  9970.2626953125\n",
      "Iteration  16 : Loss function :  9890.677734375\n",
      "Iteration  17 : Loss function :  9816.7900390625\n",
      "Iteration  18 : Loss function :  9748.1767578125\n",
      "Iteration  19 : Loss function :  9684.4638671875\n",
      "Iteration  20 : Loss function :  9625.3154296875\n",
      "Iteration  21 : Loss function :  9570.4306640625\n",
      "Iteration  22 : Loss function :  9519.53125\n",
      "Iteration  23 : Loss function :  9472.333984375\n",
      "Iteration  24 : Loss function :  9428.5703125\n",
      "Iteration  25 : Loss function :  9387.970703125\n",
      "Iteration  26 : Loss function :  9350.2783203125\n",
      "Iteration  27 : Loss function :  9315.2587890625\n",
      "Iteration  28 : Loss function :  9282.69921875\n",
      "Iteration  29 : Loss function :  9252.412109375\n",
      "Iteration  30 : Loss function :  9224.2314453125\n",
      "Iteration  31 : Loss function :  9198.0126953125\n",
      "Iteration  32 : Loss function :  9173.625\n",
      "Iteration  33 : Loss function :  9150.9482421875\n",
      "Iteration  34 : Loss function :  9129.869140625\n",
      "Iteration  35 : Loss function :  9110.28125\n",
      "Iteration  36 : Loss function :  9092.083984375\n",
      "Iteration  37 : Loss function :  9075.1806640625\n",
      "Iteration  38 : Loss function :  9059.4765625\n",
      "Iteration  39 : Loss function :  9044.8896484375\n",
      "Iteration  40 : Loss function :  9031.3349609375\n",
      "Iteration  41 : Loss function :  9018.7392578125\n",
      "Iteration  42 : Loss function :  9007.03515625\n",
      "Iteration  43 : Loss function :  8996.1572265625\n",
      "Iteration  44 : Loss function :  8986.052734375\n",
      "Iteration  45 : Loss function :  8976.669921875\n",
      "Iteration  46 : Loss function :  8967.9658203125\n",
      "Iteration  47 : Loss function :  8959.8994140625\n",
      "Iteration  48 : Loss function :  8952.43359375\n",
      "Iteration  49 : Loss function :  8945.5361328125\n",
      "Iteration  50 : Loss function :  8939.177734375\n",
      "Iteration  51 : Loss function :  8933.330078125\n",
      "Iteration  52 : Loss function :  8927.9658203125\n",
      "Iteration  53 : Loss function :  8923.05859375\n",
      "Iteration  54 : Loss function :  8918.5869140625\n",
      "Iteration  55 : Loss function :  8914.5244140625\n",
      "Iteration  56 : Loss function :  8910.8505859375\n",
      "Iteration  57 : Loss function :  8907.5400390625\n",
      "Iteration  58 : Loss function :  8904.572265625\n",
      "Iteration  59 : Loss function :  8901.9267578125\n",
      "Iteration  60 : Loss function :  8899.580078125\n",
      "Iteration  61 : Loss function :  8897.513671875\n",
      "Iteration  62 : Loss function :  8895.7041015625\n",
      "Iteration  63 : Loss function :  8894.134765625\n",
      "Iteration  64 : Loss function :  8892.783203125\n",
      "Iteration  65 : Loss function :  8891.6318359375\n",
      "Iteration  66 : Loss function :  8890.6630859375\n",
      "Iteration  67 : Loss function :  8889.857421875\n",
      "Iteration  68 : Loss function :  8889.1982421875\n",
      "Iteration  69 : Loss function :  8888.66796875\n",
      "Iteration  70 : Loss function :  8888.25\n",
      "Iteration  71 : Loss function :  8887.931640625\n",
      "Iteration  72 : Loss function :  8887.6962890625\n",
      "Iteration  73 : Loss function :  8887.5302734375\n",
      "Iteration  74 : Loss function :  8887.423828125\n",
      "Iteration  75 : Loss function :  8887.36328125\n",
      "Iteration  76 : Loss function :  8887.3388671875\n",
      "Iteration  77 : Loss function :  8887.3408203125\n",
      "Iteration  78 : Loss function :  8887.3642578125\n",
      "Iteration  79 : Loss function :  8887.3984375\n",
      "Iteration  80 : Loss function :  8887.439453125\n",
      "Iteration  81 : Loss function :  8887.48046875\n",
      "Iteration  82 : Loss function :  8887.51953125\n",
      "Iteration  83 : Loss function :  8887.55078125\n",
      "Iteration  84 : Loss function :  8887.57421875\n",
      "Iteration  85 : Loss function :  8887.5859375\n",
      "Iteration  86 : Loss function :  8887.5849609375\n",
      "Iteration  87 : Loss function :  8887.5703125\n",
      "Iteration  88 : Loss function :  8887.54296875\n",
      "Iteration  89 : Loss function :  8887.5009765625\n",
      "Iteration  90 : Loss function :  8887.4462890625\n",
      "Iteration  91 : Loss function :  8887.37890625\n",
      "Iteration  92 : Loss function :  8887.2998046875\n",
      "Iteration  93 : Loss function :  8887.2080078125\n",
      "Iteration  94 : Loss function :  8887.107421875\n",
      "Iteration  95 : Loss function :  8886.9970703125\n",
      "Iteration  96 : Loss function :  8886.8798828125\n",
      "Iteration  97 : Loss function :  8886.75390625\n",
      "Iteration  98 : Loss function :  8886.6220703125\n",
      "Iteration  99 : Loss function :  8886.484375\n",
      "RMSE (mean) on model  ICON-ESM-LR  :  0.6518127994813151\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.36328125\n",
      "Iteration  4 : Loss function :  20303.44140625\n",
      "Iteration  5 : Loss function :  18963.359375\n",
      "Iteration  6 : Loss function :  17717.60546875\n",
      "Iteration  7 : Loss function :  16625.58984375\n",
      "Iteration  8 : Loss function :  15724.5087890625\n",
      "Iteration  9 : Loss function :  15006.728515625\n",
      "Iteration  10 : Loss function :  14443.2490234375\n",
      "Iteration  11 : Loss function :  13998.0947265625\n",
      "Iteration  12 : Loss function :  13638.8828125\n",
      "Iteration  13 : Loss function :  13341.1826171875\n",
      "Iteration  14 : Loss function :  13087.8212890625\n",
      "Iteration  15 : Loss function :  12867.0244140625\n",
      "Iteration  16 : Loss function :  12670.8681640625\n",
      "Iteration  17 : Loss function :  12494.1484375\n",
      "Iteration  18 : Loss function :  12333.55859375\n",
      "Iteration  19 : Loss function :  12187.052734375\n",
      "Iteration  20 : Loss function :  12053.333984375\n",
      "Iteration  21 : Loss function :  11931.455078125\n",
      "Iteration  22 : Loss function :  11820.572265625\n",
      "Iteration  23 : Loss function :  11719.8095703125\n",
      "Iteration  24 : Loss function :  11628.2578125\n",
      "Iteration  25 : Loss function :  11545.001953125\n",
      "Iteration  26 : Loss function :  11469.185546875\n",
      "Iteration  27 : Loss function :  11400.041015625\n",
      "Iteration  28 : Loss function :  11336.904296875\n",
      "Iteration  29 : Loss function :  11279.212890625\n",
      "Iteration  30 : Loss function :  11226.4755859375\n",
      "Iteration  31 : Loss function :  11178.26171875\n",
      "Iteration  32 : Loss function :  11134.173828125\n",
      "Iteration  33 : Loss function :  11093.8447265625\n",
      "Iteration  34 : Loss function :  11056.9287109375\n",
      "Iteration  35 : Loss function :  11023.1103515625\n",
      "Iteration  36 : Loss function :  10992.103515625\n",
      "Iteration  37 : Loss function :  10963.65234375\n",
      "Iteration  38 : Loss function :  10937.53515625\n",
      "Iteration  39 : Loss function :  10913.5546875\n",
      "Iteration  40 : Loss function :  10891.541015625\n",
      "Iteration  41 : Loss function :  10871.33984375\n",
      "Iteration  42 : Loss function :  10852.80859375\n",
      "Iteration  43 : Loss function :  10835.814453125\n",
      "Iteration  44 : Loss function :  10820.234375\n",
      "Iteration  45 : Loss function :  10805.951171875\n",
      "Iteration  46 : Loss function :  10792.85546875\n",
      "Iteration  47 : Loss function :  10780.849609375\n",
      "Iteration  48 : Loss function :  10769.8427734375\n",
      "Iteration  49 : Loss function :  10759.755859375\n",
      "Iteration  50 : Loss function :  10750.517578125\n",
      "Iteration  51 : Loss function :  10742.0712890625\n",
      "Iteration  52 : Loss function :  10734.361328125\n",
      "Iteration  53 : Loss function :  10727.34375\n",
      "Iteration  54 : Loss function :  10720.9736328125\n",
      "Iteration  55 : Loss function :  10715.208984375\n",
      "Iteration  56 : Loss function :  10710.0087890625\n",
      "Iteration  57 : Loss function :  10705.3359375\n",
      "Iteration  58 : Loss function :  10701.146484375\n",
      "Iteration  59 : Loss function :  10697.404296875\n",
      "Iteration  60 : Loss function :  10694.0693359375\n",
      "Iteration  61 : Loss function :  10691.107421875\n",
      "Iteration  62 : Loss function :  10688.4853515625\n",
      "Iteration  63 : Loss function :  10686.1748046875\n",
      "Iteration  64 : Loss function :  10684.146484375\n",
      "Iteration  65 : Loss function :  10682.37890625\n",
      "Iteration  66 : Loss function :  10680.849609375\n",
      "Iteration  67 : Loss function :  10679.53515625\n",
      "Iteration  68 : Loss function :  10678.419921875\n",
      "Iteration  69 : Loss function :  10677.4814453125\n",
      "Iteration  70 : Loss function :  10676.7021484375\n",
      "Iteration  71 : Loss function :  10676.0625\n",
      "Iteration  72 : Loss function :  10675.544921875\n",
      "Iteration  73 : Loss function :  10675.130859375\n",
      "Iteration  74 : Loss function :  10674.8056640625\n",
      "Iteration  75 : Loss function :  10674.5537109375\n",
      "Iteration  76 : Loss function :  10674.357421875\n",
      "Iteration  77 : Loss function :  10674.20703125\n",
      "Iteration  78 : Loss function :  10674.0908203125\n",
      "Iteration  79 : Loss function :  10674.0\n",
      "Iteration  80 : Loss function :  10673.9248046875\n",
      "Iteration  81 : Loss function :  10673.8583984375\n",
      "Iteration  82 : Loss function :  10673.7978515625\n",
      "Iteration  83 : Loss function :  10673.734375\n",
      "Iteration  84 : Loss function :  10673.666015625\n",
      "Iteration  85 : Loss function :  10673.5888671875\n",
      "Iteration  86 : Loss function :  10673.501953125\n",
      "Iteration  87 : Loss function :  10673.400390625\n",
      "Iteration  88 : Loss function :  10673.2841796875\n",
      "Iteration  89 : Loss function :  10673.15234375\n",
      "Iteration  90 : Loss function :  10673.0068359375\n",
      "Iteration  91 : Loss function :  10672.8427734375\n",
      "Iteration  92 : Loss function :  10672.6650390625\n",
      "Iteration  93 : Loss function :  10672.4736328125\n",
      "Iteration  94 : Loss function :  10672.265625\n",
      "Iteration  95 : Loss function :  10672.0478515625\n",
      "Iteration  96 : Loss function :  10671.818359375\n",
      "Iteration  97 : Loss function :  10671.5791015625\n",
      "Iteration  98 : Loss function :  10671.3330078125\n",
      "Iteration  99 : Loss function :  10671.078125\n",
      "RMSE (mean) on model  EC-Earth3  :  0.13430003329206516\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.857421875\n",
      "Iteration  2 : Loss function :  23240.486328125\n",
      "Iteration  3 : Loss function :  21696.236328125\n",
      "Iteration  4 : Loss function :  20302.904296875\n",
      "Iteration  5 : Loss function :  18961.26953125\n",
      "Iteration  6 : Loss function :  17710.21875\n",
      "Iteration  7 : Loss function :  16603.578125\n",
      "Iteration  8 : Loss function :  15671.99609375\n",
      "Iteration  9 : Loss function :  14904.3193359375\n",
      "Iteration  10 : Loss function :  14274.9921875\n",
      "Iteration  11 : Loss function :  13757.783203125\n",
      "Iteration  12 : Loss function :  13330.53125\n",
      "Iteration  13 : Loss function :  12975.658203125\n",
      "Iteration  14 : Loss function :  12679.05078125\n",
      "Iteration  15 : Loss function :  12429.0791015625\n",
      "Iteration  16 : Loss function :  12216.1484375\n",
      "Iteration  17 : Loss function :  12032.4619140625\n",
      "Iteration  18 : Loss function :  11871.798828125\n",
      "Iteration  19 : Loss function :  11729.3076171875\n",
      "Iteration  20 : Loss function :  11601.2978515625\n",
      "Iteration  21 : Loss function :  11485.0478515625\n",
      "Iteration  22 : Loss function :  11378.619140625\n",
      "Iteration  23 : Loss function :  11280.689453125\n",
      "Iteration  24 : Loss function :  11190.376953125\n",
      "Iteration  25 : Loss function :  11107.109375\n",
      "Iteration  26 : Loss function :  11030.490234375\n",
      "Iteration  27 : Loss function :  10960.1943359375\n",
      "Iteration  28 : Loss function :  10895.9052734375\n",
      "Iteration  29 : Loss function :  10837.2646484375\n",
      "Iteration  30 : Loss function :  10783.8720703125\n",
      "Iteration  31 : Loss function :  10735.2880859375\n",
      "Iteration  32 : Loss function :  10691.0498046875\n",
      "Iteration  33 : Loss function :  10650.70703125\n",
      "Iteration  34 : Loss function :  10613.833984375\n",
      "Iteration  35 : Loss function :  10580.0615234375\n",
      "Iteration  36 : Loss function :  10549.0673828125\n",
      "Iteration  37 : Loss function :  10520.5947265625\n",
      "Iteration  38 : Loss function :  10494.427734375\n",
      "Iteration  39 : Loss function :  10470.390625\n",
      "Iteration  40 : Loss function :  10448.337890625\n",
      "Iteration  41 : Loss function :  10428.1328125\n",
      "Iteration  42 : Loss function :  10409.6494140625\n",
      "Iteration  43 : Loss function :  10392.7607421875\n",
      "Iteration  44 : Loss function :  10377.3408203125\n",
      "Iteration  45 : Loss function :  10363.267578125\n",
      "Iteration  46 : Loss function :  10350.419921875\n",
      "Iteration  47 : Loss function :  10338.6884765625\n",
      "Iteration  48 : Loss function :  10327.970703125\n",
      "Iteration  49 : Loss function :  10318.17578125\n",
      "Iteration  50 : Loss function :  10309.23046875\n",
      "Iteration  51 : Loss function :  10301.068359375\n",
      "Iteration  52 : Loss function :  10293.6376953125\n",
      "Iteration  53 : Loss function :  10286.890625\n",
      "Iteration  54 : Loss function :  10280.7900390625\n",
      "Iteration  55 : Loss function :  10275.294921875\n",
      "Iteration  56 : Loss function :  10270.37109375\n",
      "Iteration  57 : Loss function :  10265.9814453125\n",
      "Iteration  58 : Loss function :  10262.0849609375\n",
      "Iteration  59 : Loss function :  10258.6416015625\n",
      "Iteration  60 : Loss function :  10255.609375\n",
      "Iteration  61 : Loss function :  10252.947265625\n",
      "Iteration  62 : Loss function :  10250.61328125\n",
      "Iteration  63 : Loss function :  10248.5712890625\n",
      "Iteration  64 : Loss function :  10246.787109375\n",
      "Iteration  65 : Loss function :  10245.2294921875\n",
      "Iteration  66 : Loss function :  10243.8740234375\n",
      "Iteration  67 : Loss function :  10242.69921875\n",
      "Iteration  68 : Loss function :  10241.6865234375\n",
      "Iteration  69 : Loss function :  10240.818359375\n",
      "Iteration  70 : Loss function :  10240.083984375\n",
      "Iteration  71 : Loss function :  10239.466796875\n",
      "Iteration  72 : Loss function :  10238.9580078125\n",
      "Iteration  73 : Loss function :  10238.541015625\n",
      "Iteration  74 : Loss function :  10238.203125\n",
      "Iteration  75 : Loss function :  10237.9326171875\n",
      "Iteration  76 : Loss function :  10237.7138671875\n",
      "Iteration  77 : Loss function :  10237.5361328125\n",
      "Iteration  78 : Loss function :  10237.388671875\n",
      "Iteration  79 : Loss function :  10237.259765625\n",
      "Iteration  80 : Loss function :  10237.1435546875\n",
      "Iteration  81 : Loss function :  10237.033203125\n",
      "Iteration  82 : Loss function :  10236.921875\n",
      "Iteration  83 : Loss function :  10236.80859375\n",
      "Iteration  84 : Loss function :  10236.6884765625\n",
      "Iteration  85 : Loss function :  10236.5615234375\n",
      "Iteration  86 : Loss function :  10236.4267578125\n",
      "Iteration  87 : Loss function :  10236.283203125\n",
      "Iteration  88 : Loss function :  10236.12890625\n",
      "Iteration  89 : Loss function :  10235.96484375\n",
      "Iteration  90 : Loss function :  10235.7900390625\n",
      "Iteration  91 : Loss function :  10235.603515625\n",
      "Iteration  92 : Loss function :  10235.40625\n",
      "Iteration  93 : Loss function :  10235.1962890625\n",
      "Iteration  94 : Loss function :  10234.9765625\n",
      "Iteration  95 : Loss function :  10234.744140625\n",
      "Iteration  96 : Loss function :  10234.50390625\n",
      "Iteration  97 : Loss function :  10234.2568359375\n",
      "Iteration  98 : Loss function :  10234.0\n",
      "Iteration  99 : Loss function :  10233.740234375\n",
      "RMSE (mean) on model  CMCC-CM2-SR5  :  0.24318334490535518\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.853515625\n",
      "Iteration  2 : Loss function :  23240.388671875\n",
      "Iteration  3 : Loss function :  21695.4375\n",
      "Iteration  4 : Loss function :  20298.9765625\n",
      "Iteration  5 : Loss function :  18946.1796875\n",
      "Iteration  6 : Loss function :  17661.578125\n",
      "Iteration  7 : Loss function :  16480.033203125\n",
      "Iteration  8 : Loss function :  15454.2421875\n",
      "Iteration  9 : Loss function :  14638.9921875\n",
      "Iteration  10 : Loss function :  14021.02734375\n",
      "Iteration  11 : Loss function :  13545.583984375\n",
      "Iteration  12 : Loss function :  13166.564453125\n",
      "Iteration  13 : Loss function :  12851.7294921875\n",
      "Iteration  14 : Loss function :  12581.1376953125\n",
      "Iteration  15 : Loss function :  12342.8251953125\n",
      "Iteration  16 : Loss function :  12129.55078125\n",
      "Iteration  17 : Loss function :  11936.9794921875\n",
      "Iteration  18 : Loss function :  11762.5986328125\n",
      "Iteration  19 : Loss function :  11604.9072265625\n",
      "Iteration  20 : Loss function :  11462.8076171875\n",
      "Iteration  21 : Loss function :  11335.212890625\n",
      "Iteration  22 : Loss function :  11220.88671875\n",
      "Iteration  23 : Loss function :  11118.44140625\n",
      "Iteration  24 : Loss function :  11026.44921875\n",
      "Iteration  25 : Loss function :  10943.5537109375\n",
      "Iteration  26 : Loss function :  10868.552734375\n",
      "Iteration  27 : Loss function :  10800.4453125\n",
      "Iteration  28 : Loss function :  10738.4169921875\n",
      "Iteration  29 : Loss function :  10681.8212890625\n",
      "Iteration  30 : Loss function :  10630.1455078125\n",
      "Iteration  31 : Loss function :  10582.974609375\n",
      "Iteration  32 : Loss function :  10539.9521484375\n",
      "Iteration  33 : Loss function :  10500.765625\n",
      "Iteration  34 : Loss function :  10465.1201171875\n",
      "Iteration  35 : Loss function :  10432.7265625\n",
      "Iteration  36 : Loss function :  10403.302734375\n",
      "Iteration  37 : Loss function :  10376.5673828125\n",
      "Iteration  38 : Loss function :  10352.2548828125\n",
      "Iteration  39 : Loss function :  10330.12109375\n",
      "Iteration  40 : Loss function :  10309.9404296875\n",
      "Iteration  41 : Loss function :  10291.5244140625\n",
      "Iteration  42 : Loss function :  10274.7001953125\n",
      "Iteration  43 : Loss function :  10259.3271484375\n",
      "Iteration  44 : Loss function :  10245.283203125\n",
      "Iteration  45 : Loss function :  10232.4560546875\n",
      "Iteration  46 : Loss function :  10220.74609375\n",
      "Iteration  47 : Loss function :  10210.0625\n",
      "Iteration  48 : Loss function :  10200.318359375\n",
      "Iteration  49 : Loss function :  10191.4365234375\n",
      "Iteration  50 : Loss function :  10183.3427734375\n",
      "Iteration  51 : Loss function :  10175.9716796875\n",
      "Iteration  52 : Loss function :  10169.26171875\n",
      "Iteration  53 : Loss function :  10163.1611328125\n",
      "Iteration  54 : Loss function :  10157.6171875\n",
      "Iteration  55 : Loss function :  10152.5849609375\n",
      "Iteration  56 : Loss function :  10148.0244140625\n",
      "Iteration  57 : Loss function :  10143.896484375\n",
      "Iteration  58 : Loss function :  10140.1650390625\n",
      "Iteration  59 : Loss function :  10136.796875\n",
      "Iteration  60 : Loss function :  10133.7626953125\n",
      "Iteration  61 : Loss function :  10131.0361328125\n",
      "Iteration  62 : Loss function :  10128.591796875\n",
      "Iteration  63 : Loss function :  10126.41015625\n",
      "Iteration  64 : Loss function :  10124.47265625\n",
      "Iteration  65 : Loss function :  10122.7607421875\n",
      "Iteration  66 : Loss function :  10121.26171875\n",
      "Iteration  67 : Loss function :  10119.9599609375\n",
      "Iteration  68 : Loss function :  10118.83984375\n",
      "Iteration  69 : Loss function :  10117.88671875\n",
      "Iteration  70 : Loss function :  10117.0849609375\n",
      "Iteration  71 : Loss function :  10116.416015625\n",
      "Iteration  72 : Loss function :  10115.86328125\n",
      "Iteration  73 : Loss function :  10115.4130859375\n",
      "Iteration  74 : Loss function :  10115.0458984375\n",
      "Iteration  75 : Loss function :  10114.7490234375\n",
      "Iteration  76 : Loss function :  10114.5087890625\n",
      "Iteration  77 : Loss function :  10114.314453125\n",
      "Iteration  78 : Loss function :  10114.154296875\n",
      "Iteration  79 : Loss function :  10114.021484375\n",
      "Iteration  80 : Loss function :  10113.9072265625\n",
      "Iteration  81 : Loss function :  10113.806640625\n",
      "Iteration  82 : Loss function :  10113.7138671875\n",
      "Iteration  83 : Loss function :  10113.6259765625\n",
      "Iteration  84 : Loss function :  10113.537109375\n",
      "Iteration  85 : Loss function :  10113.4443359375\n",
      "Iteration  86 : Loss function :  10113.3466796875\n",
      "Iteration  87 : Loss function :  10113.2392578125\n",
      "Iteration  88 : Loss function :  10113.12109375\n",
      "Iteration  89 : Loss function :  10112.9912109375\n",
      "Iteration  90 : Loss function :  10112.84765625\n",
      "Iteration  91 : Loss function :  10112.6923828125\n",
      "Iteration  92 : Loss function :  10112.5234375\n",
      "Iteration  93 : Loss function :  10112.3408203125\n",
      "Iteration  94 : Loss function :  10112.1484375\n",
      "Iteration  95 : Loss function :  10111.9453125\n",
      "Iteration  96 : Loss function :  10111.7314453125\n",
      "Iteration  97 : Loss function :  10111.5107421875\n",
      "Iteration  98 : Loss function :  10111.279296875\n",
      "Iteration  99 : Loss function :  10111.044921875\n",
      "RMSE (mean) on model  ACCESS-CM2  :  0.25688454406638617\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.509765625\n",
      "Iteration  3 : Loss function :  21696.34375\n",
      "Iteration  4 : Loss function :  20303.359375\n",
      "Iteration  5 : Loss function :  18963.060546875\n",
      "Iteration  6 : Loss function :  17716.6328125\n",
      "Iteration  7 : Loss function :  16622.96875\n",
      "Iteration  8 : Loss function :  15718.9814453125\n",
      "Iteration  9 : Loss function :  14997.1875\n",
      "Iteration  10 : Loss function :  14428.986328125\n",
      "Iteration  11 : Loss function :  13978.6376953125\n",
      "Iteration  12 : Loss function :  13613.7197265625\n",
      "Iteration  13 : Loss function :  13309.6533203125\n",
      "Iteration  14 : Loss function :  13049.1630859375\n",
      "Iteration  15 : Loss function :  12820.4658203125\n",
      "Iteration  16 : Loss function :  12615.7470703125\n",
      "Iteration  17 : Loss function :  12430.01171875\n",
      "Iteration  18 : Loss function :  12260.2197265625\n",
      "Iteration  19 : Loss function :  12104.6162109375\n",
      "Iteration  20 : Loss function :  11962.1767578125\n",
      "Iteration  21 : Loss function :  11832.17578125\n",
      "Iteration  22 : Loss function :  11713.9169921875\n",
      "Iteration  23 : Loss function :  11606.6015625\n",
      "Iteration  24 : Loss function :  11509.3154296875\n",
      "Iteration  25 : Loss function :  11421.0888671875\n",
      "Iteration  26 : Loss function :  11340.9638671875\n",
      "Iteration  27 : Loss function :  11268.0615234375\n",
      "Iteration  28 : Loss function :  11201.603515625\n",
      "Iteration  29 : Loss function :  11140.923828125\n",
      "Iteration  30 : Loss function :  11085.4541015625\n",
      "Iteration  31 : Loss function :  11034.703125\n",
      "Iteration  32 : Loss function :  10988.23046875\n",
      "Iteration  33 : Loss function :  10945.6455078125\n",
      "Iteration  34 : Loss function :  10906.5888671875\n",
      "Iteration  35 : Loss function :  10870.7353515625\n",
      "Iteration  36 : Loss function :  10837.7939453125\n",
      "Iteration  37 : Loss function :  10807.50390625\n",
      "Iteration  38 : Loss function :  10779.640625\n",
      "Iteration  39 : Loss function :  10754.0078125\n",
      "Iteration  40 : Loss function :  10730.4306640625\n",
      "Iteration  41 : Loss function :  10708.751953125\n",
      "Iteration  42 : Loss function :  10688.8291015625\n",
      "Iteration  43 : Loss function :  10670.529296875\n",
      "Iteration  44 : Loss function :  10653.72265625\n",
      "Iteration  45 : Loss function :  10638.291015625\n",
      "Iteration  46 : Loss function :  10624.1259765625\n",
      "Iteration  47 : Loss function :  10611.123046875\n",
      "Iteration  48 : Loss function :  10599.1943359375\n",
      "Iteration  49 : Loss function :  10588.2548828125\n",
      "Iteration  50 : Loss function :  10578.2392578125\n",
      "Iteration  51 : Loss function :  10569.0859375\n",
      "Iteration  52 : Loss function :  10560.7431640625\n",
      "Iteration  53 : Loss function :  10553.162109375\n",
      "Iteration  54 : Loss function :  10546.3017578125\n",
      "Iteration  55 : Loss function :  10540.119140625\n",
      "Iteration  56 : Loss function :  10534.5712890625\n",
      "Iteration  57 : Loss function :  10529.61328125\n",
      "Iteration  58 : Loss function :  10525.2060546875\n",
      "Iteration  59 : Loss function :  10521.2978515625\n",
      "Iteration  60 : Loss function :  10517.8486328125\n",
      "Iteration  61 : Loss function :  10514.8115234375\n",
      "Iteration  62 : Loss function :  10512.1513671875\n",
      "Iteration  63 : Loss function :  10509.8271484375\n",
      "Iteration  64 : Loss function :  10507.806640625\n",
      "Iteration  65 : Loss function :  10506.0625\n",
      "Iteration  66 : Loss function :  10504.564453125\n",
      "Iteration  67 : Loss function :  10503.291015625\n",
      "Iteration  68 : Loss function :  10502.2197265625\n",
      "Iteration  69 : Loss function :  10501.3271484375\n",
      "Iteration  70 : Loss function :  10500.5947265625\n",
      "Iteration  71 : Loss function :  10500.00390625\n",
      "Iteration  72 : Loss function :  10499.53125\n",
      "Iteration  73 : Loss function :  10499.1630859375\n",
      "Iteration  74 : Loss function :  10498.8779296875\n",
      "Iteration  75 : Loss function :  10498.658203125\n",
      "Iteration  76 : Loss function :  10498.4912109375\n",
      "Iteration  77 : Loss function :  10498.36328125\n",
      "Iteration  78 : Loss function :  10498.259765625\n",
      "Iteration  79 : Loss function :  10498.173828125\n",
      "Iteration  80 : Loss function :  10498.0947265625\n",
      "Iteration  81 : Loss function :  10498.01953125\n",
      "Iteration  82 : Loss function :  10497.9384765625\n",
      "Iteration  83 : Loss function :  10497.8515625\n",
      "Iteration  84 : Loss function :  10497.75390625\n",
      "Iteration  85 : Loss function :  10497.642578125\n",
      "Iteration  86 : Loss function :  10497.515625\n",
      "Iteration  87 : Loss function :  10497.375\n",
      "Iteration  88 : Loss function :  10497.2177734375\n",
      "Iteration  89 : Loss function :  10497.0439453125\n",
      "Iteration  90 : Loss function :  10496.8544921875\n",
      "Iteration  91 : Loss function :  10496.6484375\n",
      "Iteration  92 : Loss function :  10496.4267578125\n",
      "Iteration  93 : Loss function :  10496.19140625\n",
      "Iteration  94 : Loss function :  10495.943359375\n",
      "Iteration  95 : Loss function :  10495.685546875\n",
      "Iteration  96 : Loss function :  10495.416015625\n",
      "Iteration  97 : Loss function :  10495.138671875\n",
      "Iteration  98 : Loss function :  10494.8583984375\n",
      "Iteration  99 : Loss function :  10494.5693359375\n",
      "RMSE (mean) on model  CESM2  :  0.19725483828489423\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.361328125\n",
      "Iteration  4 : Loss function :  20303.43359375\n",
      "Iteration  5 : Loss function :  18963.322265625\n",
      "Iteration  6 : Loss function :  17717.48046875\n",
      "Iteration  7 : Loss function :  16625.21484375\n",
      "Iteration  8 : Loss function :  15723.6171875\n",
      "Iteration  9 : Loss function :  15004.9775390625\n",
      "Iteration  10 : Loss function :  14440.2783203125\n",
      "Iteration  11 : Loss function :  13993.5703125\n",
      "Iteration  12 : Loss function :  13632.4990234375\n",
      "Iteration  13 : Loss function :  13332.650390625\n",
      "Iteration  14 : Loss function :  13076.8603515625\n",
      "Iteration  15 : Loss function :  12853.357421875\n",
      "Iteration  16 : Loss function :  12654.2158203125\n",
      "Iteration  17 : Loss function :  12474.2421875\n",
      "Iteration  18 : Loss function :  12310.1572265625\n",
      "Iteration  19 : Loss function :  12159.95703125\n",
      "Iteration  20 : Loss function :  12022.40625\n",
      "Iteration  21 : Loss function :  11896.6220703125\n",
      "Iteration  22 : Loss function :  11781.8203125\n",
      "Iteration  23 : Loss function :  11677.1796875\n",
      "Iteration  24 : Loss function :  11581.8310546875\n",
      "Iteration  25 : Loss function :  11494.88671875\n",
      "Iteration  26 : Loss function :  11415.5146484375\n",
      "Iteration  27 : Loss function :  11342.958984375\n",
      "Iteration  28 : Loss function :  11276.5751953125\n",
      "Iteration  29 : Loss function :  11215.8115234375\n",
      "Iteration  30 : Loss function :  11160.1953125\n",
      "Iteration  31 : Loss function :  11109.302734375\n",
      "Iteration  32 : Loss function :  11062.751953125\n",
      "Iteration  33 : Loss function :  11020.177734375\n",
      "Iteration  34 : Loss function :  10981.23828125\n",
      "Iteration  35 : Loss function :  10945.619140625\n",
      "Iteration  36 : Loss function :  10913.0234375\n",
      "Iteration  37 : Loss function :  10883.1923828125\n",
      "Iteration  38 : Loss function :  10855.8837890625\n",
      "Iteration  39 : Loss function :  10830.8916015625\n",
      "Iteration  40 : Loss function :  10808.0224609375\n",
      "Iteration  41 : Loss function :  10787.10546875\n",
      "Iteration  42 : Loss function :  10767.9765625\n",
      "Iteration  43 : Loss function :  10750.486328125\n",
      "Iteration  44 : Loss function :  10734.4921875\n",
      "Iteration  45 : Loss function :  10719.86328125\n",
      "Iteration  46 : Loss function :  10706.4765625\n",
      "Iteration  47 : Loss function :  10694.22265625\n",
      "Iteration  48 : Loss function :  10683.0009765625\n",
      "Iteration  49 : Loss function :  10672.728515625\n",
      "Iteration  50 : Loss function :  10663.330078125\n",
      "Iteration  51 : Loss function :  10654.7421875\n",
      "Iteration  52 : Loss function :  10646.908203125\n",
      "Iteration  53 : Loss function :  10639.7802734375\n",
      "Iteration  54 : Loss function :  10633.3125\n",
      "Iteration  55 : Loss function :  10627.4599609375\n",
      "Iteration  56 : Loss function :  10622.181640625\n",
      "Iteration  57 : Loss function :  10617.43359375\n",
      "Iteration  58 : Loss function :  10613.1748046875\n",
      "Iteration  59 : Loss function :  10609.365234375\n",
      "Iteration  60 : Loss function :  10605.9677734375\n",
      "Iteration  61 : Loss function :  10602.9462890625\n",
      "Iteration  62 : Loss function :  10600.267578125\n",
      "Iteration  63 : Loss function :  10597.90234375\n",
      "Iteration  64 : Loss function :  10595.82421875\n",
      "Iteration  65 : Loss function :  10594.01171875\n",
      "Iteration  66 : Loss function :  10592.439453125\n",
      "Iteration  67 : Loss function :  10591.0888671875\n",
      "Iteration  68 : Loss function :  10589.939453125\n",
      "Iteration  69 : Loss function :  10588.970703125\n",
      "Iteration  70 : Loss function :  10588.162109375\n",
      "Iteration  71 : Loss function :  10587.4970703125\n",
      "Iteration  72 : Loss function :  10586.955078125\n",
      "Iteration  73 : Loss function :  10586.5185546875\n",
      "Iteration  74 : Loss function :  10586.1708984375\n",
      "Iteration  75 : Loss function :  10585.8974609375\n",
      "Iteration  76 : Loss function :  10585.681640625\n",
      "Iteration  77 : Loss function :  10585.5126953125\n",
      "Iteration  78 : Loss function :  10585.37890625\n",
      "Iteration  79 : Loss function :  10585.26953125\n",
      "Iteration  80 : Loss function :  10585.1796875\n",
      "Iteration  81 : Loss function :  10585.09765625\n",
      "Iteration  82 : Loss function :  10585.0205078125\n",
      "Iteration  83 : Loss function :  10584.9423828125\n",
      "Iteration  84 : Loss function :  10584.859375\n",
      "Iteration  85 : Loss function :  10584.7685546875\n",
      "Iteration  86 : Loss function :  10584.6640625\n",
      "Iteration  87 : Loss function :  10584.5478515625\n",
      "Iteration  88 : Loss function :  10584.4140625\n",
      "Iteration  89 : Loss function :  10584.2666015625\n",
      "Iteration  90 : Loss function :  10584.1025390625\n",
      "Iteration  91 : Loss function :  10583.923828125\n",
      "Iteration  92 : Loss function :  10583.7294921875\n",
      "Iteration  93 : Loss function :  10583.51953125\n",
      "Iteration  94 : Loss function :  10583.2978515625\n",
      "Iteration  95 : Loss function :  10583.0634765625\n",
      "Iteration  96 : Loss function :  10582.8193359375\n",
      "Iteration  97 : Loss function :  10582.5654296875\n",
      "Iteration  98 : Loss function :  10582.3056640625\n",
      "Iteration  99 : Loss function :  10582.0380859375\n",
      "RMSE (mean) on model  CNRM-ESM2-1  :  0.16632390166496713\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.513671875\n",
      "Iteration  3 : Loss function :  21696.36328125\n",
      "Iteration  4 : Loss function :  20303.44140625\n",
      "Iteration  5 : Loss function :  18963.365234375\n",
      "Iteration  6 : Loss function :  17717.62890625\n",
      "Iteration  7 : Loss function :  16625.66015625\n",
      "Iteration  8 : Loss function :  15724.6728515625\n",
      "Iteration  9 : Loss function :  15007.044921875\n",
      "Iteration  10 : Loss function :  14443.7900390625\n",
      "Iteration  11 : Loss function :  13998.9306640625\n",
      "Iteration  12 : Loss function :  13640.09375\n",
      "Iteration  13 : Loss function :  13342.8466796875\n",
      "Iteration  14 : Loss function :  13090.017578125\n",
      "Iteration  15 : Loss function :  12869.8251953125\n",
      "Iteration  16 : Loss function :  12674.3408203125\n",
      "Iteration  17 : Loss function :  12498.34765625\n",
      "Iteration  18 : Loss function :  12338.5322265625\n",
      "Iteration  19 : Loss function :  12192.8388671875\n",
      "Iteration  20 : Loss function :  12059.958984375\n",
      "Iteration  21 : Loss function :  11938.9423828125\n",
      "Iteration  22 : Loss function :  11828.9326171875\n",
      "Iteration  23 : Loss function :  11729.0556640625\n",
      "Iteration  24 : Loss function :  11638.3955078125\n",
      "Iteration  25 : Loss function :  11556.04296875\n",
      "Iteration  26 : Loss function :  11481.1328125\n",
      "Iteration  27 : Loss function :  11412.8955078125\n",
      "Iteration  28 : Loss function :  11350.6630859375\n",
      "Iteration  29 : Loss function :  11293.865234375\n",
      "Iteration  30 : Loss function :  11242.005859375\n",
      "Iteration  31 : Loss function :  11194.6455078125\n",
      "Iteration  32 : Loss function :  11151.3837890625\n",
      "Iteration  33 : Loss function :  11111.84375\n",
      "Iteration  34 : Loss function :  11075.681640625\n",
      "Iteration  35 : Loss function :  11042.5771484375\n",
      "Iteration  36 : Loss function :  11012.2412109375\n",
      "Iteration  37 : Loss function :  10984.419921875\n",
      "Iteration  38 : Loss function :  10958.8896484375\n",
      "Iteration  39 : Loss function :  10935.4580078125\n",
      "Iteration  40 : Loss function :  10913.9541015625\n",
      "Iteration  41 : Loss function :  10894.220703125\n",
      "Iteration  42 : Loss function :  10876.12109375\n",
      "Iteration  43 : Loss function :  10859.5244140625\n",
      "Iteration  44 : Loss function :  10844.3046875\n",
      "Iteration  45 : Loss function :  10830.3505859375\n",
      "Iteration  46 : Loss function :  10817.5517578125\n",
      "Iteration  47 : Loss function :  10805.8115234375\n",
      "Iteration  48 : Loss function :  10795.0419921875\n",
      "Iteration  49 : Loss function :  10785.1640625\n",
      "Iteration  50 : Loss function :  10776.1123046875\n",
      "Iteration  51 : Loss function :  10767.8271484375\n",
      "Iteration  52 : Loss function :  10760.2578125\n",
      "Iteration  53 : Loss function :  10753.3603515625\n",
      "Iteration  54 : Loss function :  10747.0927734375\n",
      "Iteration  55 : Loss function :  10741.4140625\n",
      "Iteration  56 : Loss function :  10736.2880859375\n",
      "Iteration  57 : Loss function :  10731.67578125\n",
      "Iteration  58 : Loss function :  10727.5361328125\n",
      "Iteration  59 : Loss function :  10723.8349609375\n",
      "Iteration  60 : Loss function :  10720.5341796875\n",
      "Iteration  61 : Loss function :  10717.6005859375\n",
      "Iteration  62 : Loss function :  10714.9990234375\n",
      "Iteration  63 : Loss function :  10712.7041015625\n",
      "Iteration  64 : Loss function :  10710.6884765625\n",
      "Iteration  65 : Loss function :  10708.9296875\n",
      "Iteration  66 : Loss function :  10707.4052734375\n",
      "Iteration  67 : Loss function :  10706.09375\n",
      "Iteration  68 : Loss function :  10704.98046875\n",
      "Iteration  69 : Loss function :  10704.041015625\n",
      "Iteration  70 : Loss function :  10703.2607421875\n",
      "Iteration  71 : Loss function :  10702.619140625\n",
      "Iteration  72 : Loss function :  10702.1005859375\n",
      "Iteration  73 : Loss function :  10701.685546875\n",
      "Iteration  74 : Loss function :  10701.359375\n",
      "Iteration  75 : Loss function :  10701.1064453125\n",
      "Iteration  76 : Loss function :  10700.912109375\n",
      "Iteration  77 : Loss function :  10700.763671875\n",
      "Iteration  78 : Loss function :  10700.65234375\n",
      "Iteration  79 : Loss function :  10700.564453125\n",
      "Iteration  80 : Loss function :  10700.4951171875\n",
      "Iteration  81 : Loss function :  10700.435546875\n",
      "Iteration  82 : Loss function :  10700.380859375\n",
      "Iteration  83 : Loss function :  10700.32421875\n",
      "Iteration  84 : Loss function :  10700.2626953125\n",
      "Iteration  85 : Loss function :  10700.1943359375\n",
      "Iteration  86 : Loss function :  10700.1142578125\n",
      "Iteration  87 : Loss function :  10700.021484375\n",
      "Iteration  88 : Loss function :  10699.9130859375\n",
      "Iteration  89 : Loss function :  10699.791015625\n",
      "Iteration  90 : Loss function :  10699.6513671875\n",
      "Iteration  91 : Loss function :  10699.4970703125\n",
      "Iteration  92 : Loss function :  10699.3271484375\n",
      "Iteration  93 : Loss function :  10699.1416015625\n",
      "Iteration  94 : Loss function :  10698.9443359375\n",
      "Iteration  95 : Loss function :  10698.734375\n",
      "Iteration  96 : Loss function :  10698.513671875\n",
      "Iteration  97 : Loss function :  10698.283203125\n",
      "Iteration  98 : Loss function :  10698.0439453125\n",
      "Iteration  99 : Loss function :  10697.798828125\n",
      "RMSE (mean) on model  IPSL-CM6A-LR  :  0.11002125802287295\n",
      "Iteration  0 : Loss function :  30670.474609375\n",
      "Iteration  1 : Loss function :  25605.859375\n",
      "Iteration  2 : Loss function :  23240.5078125\n",
      "Iteration  3 : Loss function :  21696.294921875\n",
      "Iteration  4 : Loss function :  20303.037109375\n",
      "Iteration  5 : Loss function :  18961.70703125\n",
      "Iteration  6 : Loss function :  17712.08203125\n",
      "Iteration  7 : Loss function :  16610.529296875\n",
      "Iteration  8 : Loss function :  15691.7138671875\n",
      "Iteration  9 : Loss function :  14947.0693359375\n",
      "Iteration  10 : Loss function :  14348.5849609375\n",
      "Iteration  11 : Loss function :  13862.9716796875\n",
      "Iteration  12 : Loss function :  13461.3974609375\n",
      "Iteration  13 : Loss function :  13122.837890625\n",
      "Iteration  14 : Loss function :  12832.71484375\n",
      "Iteration  15 : Loss function :  12580.7998046875\n",
      "Iteration  16 : Loss function :  12359.6787109375\n",
      "Iteration  17 : Loss function :  12163.83984375\n",
      "Iteration  18 : Loss function :  11989.21484375\n",
      "Iteration  19 : Loss function :  11832.8466796875\n",
      "Iteration  20 : Loss function :  11692.5693359375\n",
      "Iteration  21 : Loss function :  11566.6943359375\n",
      "Iteration  22 : Loss function :  11453.775390625\n",
      "Iteration  23 : Loss function :  11352.4853515625\n",
      "Iteration  24 : Loss function :  11261.5634765625\n",
      "Iteration  25 : Loss function :  11179.8408203125\n",
      "Iteration  26 : Loss function :  11106.25390625\n",
      "Iteration  27 : Loss function :  11039.8583984375\n",
      "Iteration  28 : Loss function :  10979.8173828125\n",
      "Iteration  29 : Loss function :  10925.3935546875\n",
      "Iteration  30 : Loss function :  10875.921875\n",
      "Iteration  31 : Loss function :  10830.8056640625\n",
      "Iteration  32 : Loss function :  10789.509765625\n",
      "Iteration  33 : Loss function :  10751.576171875\n",
      "Iteration  34 : Loss function :  10716.61328125\n",
      "Iteration  35 : Loss function :  10684.3076171875\n",
      "Iteration  36 : Loss function :  10654.4169921875\n",
      "Iteration  37 : Loss function :  10626.7548828125\n",
      "Iteration  38 : Loss function :  10601.1806640625\n",
      "Iteration  39 : Loss function :  10577.57421875\n",
      "Iteration  40 : Loss function :  10555.83203125\n",
      "Iteration  41 : Loss function :  10535.8525390625\n",
      "Iteration  42 : Loss function :  10517.5244140625\n",
      "Iteration  43 : Loss function :  10500.736328125\n",
      "Iteration  44 : Loss function :  10485.3740234375\n",
      "Iteration  45 : Loss function :  10471.3203125\n",
      "Iteration  46 : Loss function :  10458.4658203125\n",
      "Iteration  47 : Loss function :  10446.705078125\n",
      "Iteration  48 : Loss function :  10435.9462890625\n",
      "Iteration  49 : Loss function :  10426.107421875\n",
      "Iteration  50 : Loss function :  10417.1162109375\n",
      "Iteration  51 : Loss function :  10408.91015625\n",
      "Iteration  52 : Loss function :  10401.4326171875\n",
      "Iteration  53 : Loss function :  10394.63671875\n",
      "Iteration  54 : Loss function :  10388.474609375\n",
      "Iteration  55 : Loss function :  10382.9052734375\n",
      "Iteration  56 : Loss function :  10377.8828125\n",
      "Iteration  57 : Loss function :  10373.3671875\n",
      "Iteration  58 : Loss function :  10369.318359375\n",
      "Iteration  59 : Loss function :  10365.693359375\n",
      "Iteration  60 : Loss function :  10362.4580078125\n",
      "Iteration  61 : Loss function :  10359.576171875\n",
      "Iteration  62 : Loss function :  10357.017578125\n",
      "Iteration  63 : Loss function :  10354.7509765625\n",
      "Iteration  64 : Loss function :  10352.7548828125\n",
      "Iteration  65 : Loss function :  10351.00390625\n",
      "Iteration  66 : Loss function :  10349.4775390625\n",
      "Iteration  67 : Loss function :  10348.158203125\n",
      "Iteration  68 : Loss function :  10347.025390625\n",
      "Iteration  69 : Loss function :  10346.064453125\n",
      "Iteration  70 : Loss function :  10345.2568359375\n",
      "Iteration  71 : Loss function :  10344.5869140625\n",
      "Iteration  72 : Loss function :  10344.0361328125\n",
      "Iteration  73 : Loss function :  10343.5908203125\n",
      "Iteration  74 : Loss function :  10343.2333984375\n",
      "Iteration  75 : Loss function :  10342.951171875\n",
      "Iteration  76 : Loss function :  10342.7294921875\n",
      "Iteration  77 : Loss function :  10342.5556640625\n",
      "Iteration  78 : Loss function :  10342.4189453125\n",
      "Iteration  79 : Loss function :  10342.3076171875\n",
      "Iteration  80 : Loss function :  10342.2158203125\n",
      "Iteration  81 : Loss function :  10342.1357421875\n",
      "Iteration  82 : Loss function :  10342.05859375\n",
      "Iteration  83 : Loss function :  10341.9833984375\n",
      "Iteration  84 : Loss function :  10341.9052734375\n",
      "Iteration  85 : Loss function :  10341.818359375\n",
      "Iteration  86 : Loss function :  10341.72265625\n",
      "Iteration  87 : Loss function :  10341.619140625\n",
      "Iteration  88 : Loss function :  10341.5029296875\n",
      "Iteration  89 : Loss function :  10341.375\n",
      "Iteration  90 : Loss function :  10341.2353515625\n",
      "Iteration  91 : Loss function :  10341.083984375\n",
      "Iteration  92 : Loss function :  10340.921875\n",
      "Iteration  93 : Loss function :  10340.7490234375\n",
      "Iteration  94 : Loss function :  10340.568359375\n",
      "Iteration  95 : Loss function :  10340.3779296875\n",
      "Iteration  96 : Loss function :  10340.1806640625\n",
      "Iteration  97 : Loss function :  10339.974609375\n",
      "Iteration  98 : Loss function :  10339.7646484375\n",
      "Iteration  99 : Loss function :  10339.548828125\n",
      "RMSE (mean) on model  GISS-E2-2-G  :  0.24498838276218923\n",
      "Sum of weights ==1 :  1.0\n"
     ]
    }
   ],
   "source": [
    "from cross_validation import cross_validation_procedure\n",
    "\n",
    "w, rmse, training_loss, weights = cross_validation_procedure(x,y,vars,\\\n",
    "                                                           lon_size,lat_size,notnan_idx,nan_idx,time_period=33,\\\n",
    "                                                           method='robust', rank=None, lambda_range=torch.tensor([100.0]), mu_range=torch.tensor([1000.0]),\\\n",
    "                                                           lr=1e-5,nb_gradient_iterations=100,verbose=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
